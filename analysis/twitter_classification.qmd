---
title: "twitter network analysis"
format: html
editor: visual
---

# Twitter Network

```{r}
library(tidyverse)
library(stopwords)
library(purrr)
library(corpus)
library(janitor)
library(caret)
library(rquery)

set.seed(2023)

tweets <- read_csv("raw-data/governor_twitter_May-Oct.csv")
sample <- read_csv("data/full-labelled-sample.csv")
blm_sample <- read_csv("data/labelled-blm-sample.csv")
```

# Data wrangling

```{r}

off_topic <- c('COVID', 'virus', 'social distanc', 'nurse','hospital', 'health', 'mask', 'testing', 'unemployment', 'schools', 'positive', 'PPE', 'ballot', 'vote', 'census', 'symptom', 'pandemic', 'econom', 'Doctor')

#filter out unrelated tweets from entire sample
tweets_filtered <- tweets %>% 
  filter(!grepl(paste(off_topic, collapse = "|"), text))

#label positive tweets out of possible tweets
tweets_blm_filtered <- tweets_filtered %>% 
  filter(grepl(paste(on_topic, collapse = "|"), text)) %>% #removing all uncategorized tweets
  mutate(topic_blm = 1) %>% 
  mutate(time = as.character(time))

tweets_blm_filtered <- tweets_blm_filtered %>% 
  anti_join(sample, by = "x1")

#merge positive instances with labelled sample
full_sample <- sample %>% 
  natural_join(tweets_blm_filtered, by = "x1", jointype = "FULL") %>% 
  mutate(text = tolower(text))

full_sample$...1 <- NULL
full_sample$...2 <- NULL

#write.csv(full_sample, "data/full-labelled-sample.csv")
#write.csv(tweets_blm_filtered, "data/blm-sample.csv")
```

#Divide into training and testing samples

```{r}
train <- sample(1:nrow(full_sample), round(0.7*nrow(full_sample),0), F)

d_train <- full_sample[train,]
d_test <- full_sample[-train,]
```

# Define dictionary function

credit https://www.r-bloggers.com/2021/11/detecting-topics-in-mails-tweets-etc-how-to-create-a-text-classification-algorithm-in-r/

```{r}
create_dictionary <- function(data){
  corpus <- data$text
  
  #split up words and convert to lowercase
  corpus <- purrr::map(corpus, function(x) str_split(tolower(x),"\\s+") %>% unlist) 
  
  #remove non-letters
  corpus <- purrr::map(corpus, function(x) gsub("[^a-z]","",x))
  
  #remove stop-words ("the", "in", etc.)
  corpus <- purrr::map(corpus, function(x) x[!(x %in% stopwords::stopwords("en"))])
  
  #stem all words (eg sentences -> sentenc)
  corpus <- purrr::map(corpus, function(x) text_tokens(x, stemmer="en") %>% unlist)
  
  #keep only words occurring 20+
  words <- as.data.frame(sort(table(unlist(corpus)), decreasing=T), stringsAsFactors = F)
  words <- words$Var1[which(words$Freq >=20)]
  
  return(words)  
}
```

# Create dictionary on training data

```{r}
dict_train <- create_dictionary(d_train)
```

# Define document-term-matrix function

```{r}
create_dtm <- function(data, dict) {
  corpus <- data$text
  
  #Repeat pre-processing from above
  corpus <- purrr::map(corpus, function(x) str_split(tolower(x),"\\s+") %>% unlist) 
  corpus <- purrr::map(corpus, function(x) gsub("[^a-z]","",x))
  corpus <- purrr::map(corpus, function(x) x[!(x %in% stopwords::stopwords("en"))])
  corpus <- purrr::map(corpus, function(x) text_tokens(x, stemmer="en") %>% unlist)
  
  #Keep only words from the dictionary
  corpus <- purrr::map(corpus, function(x) x[x %in% dict])
  
  #Make dtm
  dtm <- as.data.frame(matrix(0L, nrow=nrow(data), ncol=length(dict)))
  names(dtm) <- dict
  
  freq <- purrr::map(corpus, table)
  for (i in 1:nrow(dtm)){
    dtm[i, names(freq[[i]])] <- unname(freq[[i]])
  }
  
  return(dtm)
}
```

# Create DTM

```{r}
dtm_train <- create_dtm(d_train, dict_train)
```

# Define binary classification algorithm

```{r}
train_model <- function(data, dtm, target_topic){
 t <- factor(unlist(data[,target_topic]), levels=c(1,0))
 
 caret::train(dtm, t, method="xgbTree",
                     trControl = trainControl(method="cv", number=5, 
                                              search = "random", 
                                              verboseIter=T))
}
```

# Run classification

```{r}
set.seed(2023)
mod <- train_model(d_train, dtm_train, "topic_blm")
mod
```

# Define evaluation function

```{r}
evaluate_model <- function(model, data_test, dict, target_topic){
  t <- factor(unlist(data_test[,target_topic]), levels=c(1,0))
  dtm_test <- create_dtm(data_test, dict)
  
  predictions <- predict(mod, newdata = dtm_test)
  confusionMatrix(predictions, t)
  
}
```

#Evaluate model accuracy

```{r}
evaluate_model(mod, d_test, dict_train, "topic_blm")
```

# Check misclassifications

```{r}
dtm_test <- create_dtm(d_test, dict_train)
predictions <- predict(mod, newdata = dtm_test)

#false positives
d_test[which(d_test$topic_blm == 0 & predictions == 1),][,] %>% View

#false negatives
d_test[which(d_test$topic_blm == 1 & predictions == 0),][,] %>% View

#~90 sensitivity
#~96 specificity 
```

# Run on all data

```{r}
#create dictionary of terms on all data
#dict_full <- create_dictionary(tweets_filtered)

#create document term matrix on full data 
dtm_full <- create_dtm(tweets_filtered, dict_train)

#run existing model 
full_predictions <- predict(mod, newdata = dtm_full)

#save as df
blm_topic_predictions <- tweets_filtered[which(full_predictions == 1),][,] 

write.csv(blm_topic_predictions, "data/")

```

# Classify opinions

```{r}
additional_blm_tweets <- read_csv("data/labelled-blm-sample.csv") |>
  select(-1) |>
  rename(id = "x1")

sample_clean <- sample |>
  select(-c(1, 2)) |>
  rename(id = "x1")

#merge with other labeled sample
merged <- rbind(sample_clean, additional_blm_tweets)
merged <- merged |>
  mutate(topic = case_when(topic_blm == 0 ~ "irrelevant",
                   (for_blm == 1 & against_blm == 1) ~ "for and against",
                   for_blm == 1 ~ "for",
                   against_blm == 1 ~ "against",
                   topic_blm == 1 ~ "blm"
                   ),
         topic_numeric = case_when(topic == "irrelevant" ~ 0,
                                   topic == "blm" ~ 1,
                                   topic == "for" ~ 2,
                                   topic == "against" ~ 3,
                                   topic == "for and against" ~ 4
                                   )
  )
```

```{r}
# split into train and test
train_pf <- sample(1:nrow(merged), round(0.7*nrow(merged),0), F)
d_train_pf <- merged[train,]
d_test_pf <- merged[-train,]
```

```{r}
dict_train_pf <- create_dictionary(d_train_pf)
```

```{r}
dtm_train_pf <- create_dtm(d_train_pf, dict_train_pf)
```

```{r}
# train the model
# https://rpubs.com/mharris/multiclass_xgboost

xgb_params <- list("objective" = "multi:softprob",
                   "eval_metric" = "mlogloss",
                   "num_class" = 5)
train_model_pf <- function(data, dtm, target_topic) {
  
 t <- factor(unlist(data[,target_topic]), levels=c(0, 1, 2, 3, 4))
 
 caret::train(dtm, t, method="xgbTree",
                     trControl = trainControl(method="cv", number=5, 
                                              search = "random", 
                                              verboseIter=T))
}

mod <- train_model_pf(d_train_pf, dtm_train_pf, "topic_numeric")
mod


```

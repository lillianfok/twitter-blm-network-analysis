---
title: "twitter network analysis"
format: html
editor: visual
---

# Twitter Network

```{r}
library(tidyverse)
library(stopwords)
library(purrr)
library(corpus)
library(janitor)
library(caret)
library(rquery)

set.seed(2023)

tweets <- read_csv("data/senator_twitter_May-Oct.csv")

sample <- read_csv("data/full-labelled-sample.csv")
```


# Data wrangling 
```{r}
tweets <- tweets %>% 
#  sample_n(1500) %>% 
  clean_names() %>% 
  select(x1, text, time, name, party) %>%
  add_column(for_blm = NA) %>% 
  add_column(against_blm = NA) 

off_topic <- c('COVID', 'virus', 'social distanc', 'nurse','hospital', 'health', 'mask', 'testing', 'unemployment', 'schools', 'positive', 'PPE', 'ballot', 'vote', 'census', 'symptom', 'pandemic', 'econom', 'Doctor')

on_topic <- c('Floyd', 'Breonna', 'Breonna Taylor', 'BLM', 'blm', 'Black Lives Matter', 'lack lives matter', 'protest', 'justice', 'racis', 'law enforcement', 'police', '#BackTheBlue')

#filter out unrelated tweets from entire sample
tweets_filtered <- tweets %>% 
  filter(!grepl(paste(off_topic, collapse = "|"), text))

########try filtering out from sample too
# sample <- sample %>% 
#   filter(!grepl(paste(off_topic, collapse = "|"), text))
# 
# sample$...1 <- NULL
# sample$...2 <- NULL

#label positive tweets out of possible tweets
tweets_blm_filtered <- tweets_filtered %>% 
  filter(grepl(paste(on_topic, collapse = "|"), text)) %>% #removing all uncategorized tweets
  mutate(topic_blm = 1) %>% 
  mutate(time = as.character(time))

tweets_blm_filtered <- tweets_blm_filtered %>% 
  anti_join(sample, by = "x1")

#merge positive instances with labelled sample
full_sample <- sample %>% 
  natural_join(tweets_blm_filtered, by = "x1", jointype = "FULL") %>% 
  mutate(text = tolower(text))

full_sample$...1 <- NULL
full_sample$...2 <- NULL

write.csv(full_sample, "data/full-labelled-sample.csv")
write.csv(tweets_blm_filtered, "data/blm-sample.csv")

```


#Divide into training and testing samples
```{r}
train <- sample(1:nrow(full_sample), round(0.7*nrow(full_sample),0), F)

d_train <- full_sample[train,]
d_test <- full_sample[-train,]
```


# Define dictionary function
credit https://www.r-bloggers.com/2021/11/detecting-topics-in-mails-tweets-etc-how-to-create-a-text-classification-algorithm-in-r/ 
```{r}
create_dictionary <- function(data){
  corpus <- data$text
  
  #split up words and convert to lowercase
  corpus <- purrr::map(corpus, function(x) str_split(tolower(x),"\\s+") %>% unlist) 
  
  #remove non-letters
  corpus <- purrr::map(corpus, function(x) gsub("[^a-z]","",x))
  
  #remove stop-words ("the", "in", etc.)
  corpus <- purrr::map(corpus, function(x) x[!(x %in% stopwords::stopwords("en"))])
  
  #stem all words (eg sentences -> sentenc)
  corpus <- purrr::map(corpus, function(x) text_tokens(x, stemmer="en") %>% unlist)
  
  #keep only words occurring 20+
  words <- as.data.frame(sort(table(unlist(corpus)), decreasing=T), stringsAsFactors = F)
  words <- words$Var1[which(words$Freq >=20)]
  
  return(words)  
}
```


# Create dictionary on training data
```{r}
dict_train <- create_dictionary(d_train)
```


# Define document-term-matrix function
```{r}
create_dtm <- function(data, dict){
  corpus <- data$text
  
  #Repeat pre-processing from above
  corpus <- purrr::map(corpus, function(x) str_split(tolower(x),"\\s+") %>% unlist) 
  corpus <- purrr::map(corpus, function(x) gsub("[^a-z]","",x))
  corpus <- purrr::map(corpus, function(x) x[!(x %in% stopwords::stopwords("en"))])
  corpus <- purrr::map(corpus, function(x) text_tokens(x, stemmer="en") %>% unlist)
  
  #Keep only words from the dictionary
  corpus <- purrr::map(corpus, function(x) x[x %in% dict])
  
  #Make dtm
  dtm <- as.data.frame(matrix(0L, nrow=nrow(data), ncol=length(dict)))
  names(dtm) <- dict
  
  freq <- purrr::map(corpus, table)
  for (i in 1:nrow(dtm)){
    dtm[i, names(freq[[i]])] <- unname(freq[[i]])
  }
  
  return(dtm)
}
```


# Create DTM
```{r}
dtm_train <- create_dtm(d_train, dict_train)
```


# Define binary classification algorithm
```{r}
train_model <- function(data, dtm, target_topic){
 t <- factor(unlist(data[,target_topic]), levels=c(1,0))
 
 caret::train(dtm, t, method="xgbTree",
                     trControl = trainControl(method="cv", number=5, 
                                              search = "random", 
                                              verboseIter=T))
}
```


# Run classification
```{r}
set.seed(2023)
mod <- train_model(d_train, dtm_train, "topic_blm")
mod
```


# Define evaluation function
```{r}
evaluate_model <- function(model, data_test, dict, target_topic){
  t <- factor(unlist(data_test[,target_topic]), levels=c(1,0))
  dtm_test <- create_dtm(data_test, dict)
  
  predictions <- predict(mod, newdata = dtm_test)
  confusionMatrix(predictions, t)
  
}
```


#Evaluate model accuracy
```{r}
evaluate_model(mod, d_test, dict_train, "topic_blm")
```


# Check misclassifications
```{r}
dtm_test <- create_dtm(d_test, dict_train)
predictions <- predict(mod, newdata = dtm_test)

#false positives
d_test[which(d_test$topic_blm == 0 & predictions == 1),][,] %>% View

#false negatives
d_test[which(d_test$topic_blm == 1 & predictions == 0),][,] %>% View

#~90 sensitivity
#~96 specificity 
```

# Classify opinions

```{r}
additional_blm_tweets <- read_csv("data/blm-sample.csv")

#merge with other labelled sample

```



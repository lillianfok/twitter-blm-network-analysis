---
title: "twitter network analysis"
format: html
editor: visual
---

# Twitter Network

```{r}
library(tidyverse)
library(stopwords)
library(purrr)
library(corpus)
library(janitor)
library(caret)

tweets <- read_csv("data/senator_twitter_May-Oct.csv")

full_sample <- read_csv("data/full-labelled-sample.csv")
```

# Data wrangling (DON'T RUN)
```{r}
set.seed(2023)
tweets <- tweets %>% 
  sample_n(1500) %>% 
  clean_names() %>% 
  select(x1, text, time, name, party) %>% 
  add_column(for_blm = NA) %>% 
  add_column(against_blm = NA) 

#filters <- c('COVID', 'virus', 'social distanc', 'nurse', 'healthcare', 'hospital', 'health', 'mask', 'testing', 'unemployment', 'schools', 'PPE', 'ballot', 'vote', 'census', 'symptom')

#filtered_sample_tweets <- tweets %>% 
#  filter(!grepl(paste(covid, collapse = "|"), text))


labelled_extra_sample <- read_csv("data/labelled-extra-sample.csv")
labelled_filtered_sample <- read_csv("data/labelled-filtered-sample.csv")

full_sample <- labelled_filtered_sample %>% 
  natural_join(labelled_extra_sample, by = "x1", jointype = "FULL") %>% 
  select (-c(...1, ...2, ...7, party.y, text.y, time.y, name.y)) %>% 
    mutate(name = case_when(!is.na(name) ~ name,
                          is.na(name) ~ name.x)) %>% 
  mutate(text = case_when(!is.na(text) ~ text,
                          is.na(text) ~ text.x)) %>% 
  mutate(party = case_when(!is.na(party) ~ party,
                          is.na(party) ~ party.x)) %>% 
  mutate(time = case_when(!is.na(time) ~ time,
                          is.na(time) ~ time.x)) %>% 
  select(x1, time, text, name, party, for_blm, against_blm, topic_blm)

#write.csv(full_sample, 'data/full-labelled-sample.csv')
```


#Divide into training and testing samples
```{r}
train <- sample(1:nrow(full_sample), round(0.7*nrow(full_sample),0), F)

d_train <- full_sample[train,]
d_test <- full_sample[-train,]
```


# Define dictionary function
credit https://www.r-bloggers.com/2021/11/detecting-topics-in-mails-tweets-etc-how-to-create-a-text-classification-algorithm-in-r/ 
```{r}
create_dictionary <- function(data){
  corpus <- data$text
  
  #split up words and convert to lowercase
  corpus <- purrr::map(corpus, function(x) str_split(tolower(x),"\\s+") %>% unlist) 
  
  #remove non-letters
  corpus <- purrr::map(corpus, function(x) gsub("[^a-z]","",x))
  
  #remove stop-words ("the", "in", etc.)
  corpus <- purrr::map(corpus, function(x) x[!(x %in% stopwords::stopwords("en"))])
  
  #stem all words (eg sentences -> sentenc)
  corpus <- purrr::map(corpus, function(x) text_tokens(x, stemmer="en") %>% unlist)
  
  #keep only words occurring 20+
  words <- as.data.frame(sort(table(unlist(corpus)), decreasing=T), stringsAsFactors = F)
  words <- words$Var1[which(words$Freq >=20)]
  
  return(words)  
}
```


# Create dictionary on training data
```{r}
dict_train <- create_dictionary(d_train)
```


# Define document-term-matrix function
```{r}
create_dtm <- function(data, dict){
  corpus <- data$text
  
  #Repeat pre-processing from above
  corpus <- purrr::map(corpus, function(x) str_split(tolower(x),"\\s+") %>% unlist) 
  corpus <- purrr::map(corpus, function(x) gsub("[^a-z]","",x))
  corpus <- purrr::map(corpus, function(x) x[!(x %in% stopwords::stopwords("en"))])
  corpus <- purrr::map(corpus, function(x) text_tokens(x, stemmer="en") %>% unlist)
  
  #Keep only words from the dictionary
  corpus <- purrr::map(corpus, function(x) x[x %in% dict])
  
  #Make dtm
  dtm <- as.data.frame(matrix(0L, nrow=nrow(data), ncol=length(dict)))
  names(dtm) <- dict
  
  freq <- purrr::map(corpus, table)
  for (i in 1:nrow(dtm)){
    dtm[i, names(freq[[i]])] <- unname(freq[[i]])
  }
  
  return(dtm)
}
```


# Create DTM
```{r}
dtm_train <- create_dtm(d_train, dict_train)
```


# Define binary classification algorithm
```{r}
train_model <- function(data, dtm, target_topic){
 t <- factor(unlist(data[,target_topic]), levels=c(1,0))
 
 caret::train(dtm, t, method="xgbTree",
                     trControl = trainControl(method="cv", number=5, 
                                              search = "random", 
                                              verboseIter=T))
}
```


# Run classification
```{r}
set.seed(2023)
mod <- train_model(d_train, dtm_train, "topic_blm")
mod
```


# Define evaluation function
```{r}
evaluate_model <- function(model, data_test, dict, target_topic){
  t <- factor(unlist(data_test[,target_topic]), levels=c(1,0))
  dtm_test <- create_dtm(data_test, dict)
  
  predictions <- predict(mod, newdata = dtm_test)
  confusionMatrix(predictions, t)
  
}
```


#Evaluate model accuracy
```{r}
evaluate_model(mod, d_test, dict_train, "topic_blm")
```


# Check misclassifications
```{r}
dtm_test <- create_dtm(d_test, dict_train)
predictions <- predict(mod, newdata = dtm_test)

#false positives
d_test[which(d_test$topic_blm == 0 & predictions == 1),][,] %>% View

#false negatives
d_test[which(d_test$topic_blm == 1 & predictions == 0),][,] %>% View
```

#Model for multiple topics

